{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D-GAN-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmxEe0AEtRiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f8e8c2ad-11c6-4fc4-a5dc-33b8e5431808"
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchsummary\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ue1BlbIxDsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ac224250-82c9-4e4a-f702-a180dbc8d053"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "\"\"\"\n",
        "Implementation based on original paper NeurIPS 2016 https://papers.nips.cc/paper/6096-learning-a-probabilistic-latent-space-of-object-shapes-via-3d-generative-adversarial-modeling.pdf\n",
        "\"\"\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nImplementation based on original paper NeurIPS 2016 https://papers.nips.cc/paper/6096-learning-a-probabilistic-latent-space-of-object-shapes-via-3d-generative-adversarial-modeling.pdf\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdWpJZhRxNVC",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p3oPTztxLqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, in_channels=3, dim=64, out_conv_channels=512):\n",
        "        super(Discriminator, self).__init__()\n",
        "        conv1_channels = int(out_conv_channels / 8)\n",
        "        conv2_channels = int(out_conv_channels / 4)\n",
        "        conv3_channels = int(out_conv_channels / 2)\n",
        "        self.out_conv_channels = out_conv_channels\n",
        "        self.out_dim = int(dim / 16)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv3d(\n",
        "                in_channels=in_channels, out_channels=conv1_channels, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(conv1_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv3d(\n",
        "                in_channels=conv1_channels, out_channels=conv2_channels, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(conv2_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv3d(\n",
        "                in_channels=conv2_channels, out_channels=conv3_channels, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(conv3_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv3d(\n",
        "                in_channels=conv3_channels, out_channels=out_conv_channels, kernel_size=4,\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(out_conv_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(out_conv_channels * self.out_dim * self.out_dim * self.out_dim, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # Flatten and apply linear + sigmoid\n",
        "        x = x.view(-1, self.out_conv_channels * self.out_dim * self.out_dim * self.out_dim)\n",
        "        x = self.out(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDCCLjoaxW5B",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwYhui5IxY6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, in_channels=512, out_dim=64, out_channels=1, noise_dim=200, activation=\"sigmoid\"):\n",
        "        super(Generator, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_dim = out_dim\n",
        "        self.in_dim = int(out_dim / 16)\n",
        "        conv1_out_channels = int(self.in_channels / 2.0)\n",
        "        conv2_out_channels = int(conv1_out_channels / 2)\n",
        "        conv3_out_channels = int(conv2_out_channels / 2)\n",
        "\n",
        "        self.linear = torch.nn.Linear(noise_dim, in_channels * self.in_dim * self.in_dim * self.in_dim)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(\n",
        "                in_channels=in_channels, out_channels=conv1_out_channels, kernel_size=(4, 4, 4),\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(conv1_out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(\n",
        "                in_channels=conv1_out_channels, out_channels=conv2_out_channels, kernel_size=(4, 4, 4),\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(conv2_out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(\n",
        "                in_channels=conv2_out_channels, out_channels=conv3_out_channels, kernel_size=(4, 4, 4),\n",
        "                stride=2, padding=1, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm3d(conv3_out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(\n",
        "                in_channels=conv3_out_channels, out_channels=out_channels, kernel_size=(4, 4, 4),\n",
        "                stride=2, padding=1, bias=False\n",
        "            )\n",
        "        )\n",
        "        if activation == \"sigmoid\":\n",
        "            self.out = torch.nn.Sigmoid()\n",
        "        else:\n",
        "            self.out = torch.nn.Tanh()\n",
        "\n",
        "    def project(self, x):\n",
        "        \"\"\"\n",
        "        projects and reshapes latent vector to starting volume\n",
        "        :param x: latent vector\n",
        "        :return: starting volume\n",
        "        \"\"\"\n",
        "        return x.view(-1, self.in_channels, self.in_dim, self.in_dim, self.in_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.project(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        return self.out(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2GyllAQxc-R",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmJJv8VwxfCC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22d77bc2-ea30-4298-d2f2-b2ef203494ba"
      },
      "source": [
        "def test_gan3d(print_summary=True):\n",
        "    noise_dim = 200 # latent space vector dim\n",
        "    in_channels = 512 # convolutional channels\n",
        "    dim = 64  # cube volume\n",
        "    model_generator = Generator(in_channels=512, out_dim=dim, out_channels=1, noise_dim=noise_dim)\n",
        "    noise = torch.rand(1, noise_dim)\n",
        "    generated_volume = model_generator(noise)\n",
        "    print(\"Generator output shape\", generated_volume.shape)\n",
        "    model_discriminator = Discriminator(in_channels=1, dim=dim, out_conv_channels=in_channels)\n",
        "    out = model_discriminator(generated_volume)\n",
        "    print(\"Discriminator output\", out.item())\n",
        "    if print_summary:\n",
        "      print(\"\\n\\nGenerator summary\\n\\n\")\n",
        "      summary(model_generator, (1, noise_dim))\n",
        "      print(\"\\n\\nDiscriminator summary\\n\\n\")\n",
        "      summary(model_discriminator, (1,dim,dim,dim))\n",
        "\n",
        "test_gan3d()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator output shape torch.Size([1, 1, 64, 64, 64])\n",
            "Discriminator output 0.47117894887924194\n",
            "\n",
            "\n",
            "Generator summary\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1             [-1, 1, 32768]       6,586,368\n",
            "   ConvTranspose3d-2         [-1, 256, 8, 8, 8]       8,388,608\n",
            "       BatchNorm3d-3         [-1, 256, 8, 8, 8]             512\n",
            "              ReLU-4         [-1, 256, 8, 8, 8]               0\n",
            "   ConvTranspose3d-5      [-1, 128, 16, 16, 16]       2,097,152\n",
            "       BatchNorm3d-6      [-1, 128, 16, 16, 16]             256\n",
            "              ReLU-7      [-1, 128, 16, 16, 16]               0\n",
            "   ConvTranspose3d-8       [-1, 64, 32, 32, 32]         524,288\n",
            "       BatchNorm3d-9       [-1, 64, 32, 32, 32]             128\n",
            "             ReLU-10       [-1, 64, 32, 32, 32]               0\n",
            "  ConvTranspose3d-11        [-1, 1, 64, 64, 64]           4,096\n",
            "          Sigmoid-12        [-1, 1, 64, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 17,601,408\n",
            "Trainable params: 17,601,408\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 67.25\n",
            "Params size (MB): 67.14\n",
            "Estimated Total Size (MB): 134.39\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "Discriminator summary\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1       [-1, 64, 32, 32, 32]           4,096\n",
            "       BatchNorm3d-2       [-1, 64, 32, 32, 32]             128\n",
            "         LeakyReLU-3       [-1, 64, 32, 32, 32]               0\n",
            "            Conv3d-4      [-1, 128, 16, 16, 16]         524,288\n",
            "       BatchNorm3d-5      [-1, 128, 16, 16, 16]             256\n",
            "         LeakyReLU-6      [-1, 128, 16, 16, 16]               0\n",
            "            Conv3d-7         [-1, 256, 8, 8, 8]       2,097,152\n",
            "       BatchNorm3d-8         [-1, 256, 8, 8, 8]             512\n",
            "         LeakyReLU-9         [-1, 256, 8, 8, 8]               0\n",
            "           Conv3d-10         [-1, 512, 4, 4, 4]       8,388,608\n",
            "      BatchNorm3d-11         [-1, 512, 4, 4, 4]           1,024\n",
            "        LeakyReLU-12         [-1, 512, 4, 4, 4]               0\n",
            "           Linear-13                    [-1, 1]          32,769\n",
            "          Sigmoid-14                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 11,048,833\n",
            "Trainable params: 11,048,833\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.00\n",
            "Forward/backward pass size (MB): 63.75\n",
            "Params size (MB): 42.15\n",
            "Estimated Total Size (MB): 106.90\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}